<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-148953677-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-148953677-1');
</script>

## Welcome to Mohna Chakraborty's homepage
<span style="font-size:1.35em;">
I am a fourth year Ph.D. student at the Department of Computer Science at Iowa State University. I am working as a Research Assistant at the <a href="https://sites.google.com/iastate.edu/qili/publications"> Data Mining and Knowledge Lab</a>. My supervisor is <a href="https://sites.google.com/iastate.edu/qili/">Dr. Qi Li</a>. Also, I have worked as a Data Science intern at The Home Depot, Epsilon and as Data Analytics intern at Delaware North. My research interests are in the domain of data mining, natural language processing, and machine learning. Through my research, I have contributed several key methods in top conferences and workshops like ACL' 2023, UAI' 2023, SIGKDD' 2022, ESEC/FSE'2021 and workshops like RANLP'2021.</span>


## Publications

<span style="font-size:1.35em;">
<b><font color="red">2023</font></b><br>
<b>Mohna Chakraborty</b> , Adithya Kulkarni, and Qi Li.
Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts,
<b>ACL, 2023</b> [<a 
href="https://aclanthology.org/2023.acl-long.313"><span style='color:#954F72'>paper</span></a>]
<br><br> 
Adithya Kulkarni, <b>Mohna Chakraborty</b> and Qi Li.
Optimal Budget Allocation for Crowdsourcing Labels for Graphs,
<b>UAI, 2023</b> [<a 
href="https://proceedings.mlr.press/v216/kulkarni23a.html"><span style='color:#954F72'>paper</span></a>]
<br><br> 

<span style="font-size:1.35em;">
<b><font color="red">2022</font></b><br>
<b>Mohna Chakraborty</b> , Adithya Kulkarni, and Qi Li.
Open-Domain Aspect-Opinion Co-Mining with Double-Layer Span Extraction,
<b>SIGKDD, 2022</b> [<a 
href="https://doi.org/10.1145/3534678.3539386"><span style='color:#954F72'>paper</span></a>]
<br><br> 

<span style="font-size:1.35em;">
<b><font color="red">2021</font></b><br>
Richard D Jiles, <b>Mohna Chakraborty</b>.
[Re] Domain Generalization using Causal Matching,
<b>ML Reproducibility Challenge, 2021</b>: [<a 
href="https://openreview.net/forum?id=r43elaGmhCY"><span style='color:#954F72'>paper</span></a>]
<br><br>
Abhishek Kumar Mishra, <b>Mohna Chakraborty</b>. Does local pruning offer task-specific models to learn effectively?,
<b>Proceedings of the Student Research Workshop Associated with RANLP, 2021</b>: [<a
href="https://aclanthology.org/2021.ranlp-srw.17"><span style='color:#954F72'>paper</span></a>]
<br><br>
<b>Mohna Chakraborty</b>. Does reusing pre-trained NLP model propagate bugs?,
<b>ESEC/FSE, 2021</b>: [<a
href="https://doi.org/10.1145/3468264.3473494"><span style='color:#954F72'>paper</span></a>]
<br><br>


## Recent News!
<span style="font-size:1.35em;">
<br> <b>Nov '23</b>: I served as Review member at EACL 2023.<br>
<br> <b>Oct '23</b>: Awarded Best Research Poster Award for my paper “Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts” at MINK WIC (Missouri, Iowa, Nebraska, Kansas Women in Computing) Conference.<br>
<br> <b>Oct '23</b>: Selected to represent Iowa State University at MINK WIC (An ACM celebration of Women in Computing) Conference.<br>
<br> <b>Oct '23</b>: Defended my Preliminary Exam on Analysis of Textual-based Reviews with Minimal Supervision.<br>
<br> <b>Oct '23</b>: Serving as a mentor for an undergraduate student at Iowa State University for the McNair program.<br>
<br> <b>Oct '23</b>: I have taught a graduate-level course at Iowa State University as a guest lecturer for COM S 571X (Responsible AI: Risk Management in Data Driven Discovery.) to teach the students about representation learning, transformer models, and future research directions to develop trustworthy machine learning methods for natural language processing.<br>
<br> <b>May '23</b>: Joined The Home Depot as a Data Science intern.<br>
<br> <b>May '23</b>: Our paper on "Optimal Budget Allocation for Crowdsourcing Labels for Graphs" has been accepted at UAI 2023.<br>
<br> <b>May '23</b>: Our paper on "Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts" has been accepted at ACL 2023.<br>
<br> <b>March '23</b>: Awarded 2nd position for 7th Annual Research Competition at Iowa State University.<br>
<b>Sep '22</b>: Selected to represent Iowa State University for the prestigious and competitive Grace Hopper Celebration.<br>
<br> <b>Aug '21</b>: Presented our paper and poster "Open-Domain Aspect-Opinion Co-Mining with Double-Layer Span Extraction", at the SIGKDD, 2022 conference in Washington D.C.<br>
<br> <b>Aug '22</b>: Awarded Student Travel Award for SIGKDD 2022.<br>
<br> <b>July '22</b>: I served as Review member at HCOMP 2022.<br>
<br> <b>July '22</b>: I served as Review member at EMNLP 2022.<br>
<br> <b>May '22</b>: Our paper on "Open-Domain Aspect-Opinion Co-Mining with Double-Layer Span Extraction" has been accepted at SIGKDD 2022.<br>
<br> <b>May '22</b>: Joined Epsilon as a PhD intern.<br>
<br> <b>April '22</b>: Defended my research proficiency on Weakly Supervised Review Analysis Based on Task Correlation.<br>
<br> <b>March '22</b>: Awarded 1st position for 6th Annual Research Competition at Iowa State University.<br>
<br> <b>March '22</b>: Our paper on "[Re] Domain Generalization using Causal Matching" has been accepted at ML Reproducibility Challenge 2021 (Fall Edition).<br>
<br> <b>Dec '21</b>: Served as Review member at PAKDD 2021.<br>
<br> <b>Sep '21</b>: Our paper on "Does local pruning offer task-specific models to learn effectively?" has been accepted at RANLP 2021.<br>
<br> <b>Aug '21</b>: Present SRC paper "Does reusing pre-trained NLP model propagate bugs?", ESEC/FSE, 2021.<br>
<br> <b>June '21</b>: Our paper on "Does reusing pre-trained NLP model propagate bugs?" has been accepted at ESEC/FSE, SRC 2021.<br>
<br> <b>May '21</b>: Joined Epsilon as a PhD intern.<br>
<br> <b>Aug '20</b>: Joined Ph.D. program at the Department of Computer Science at Iowa State University.<br></span>


